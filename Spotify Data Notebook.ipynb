{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ea106",
   "metadata": {
    "id": "662ea106"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import os.path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "U-wHnUm3kYnZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U-wHnUm3kYnZ",
    "outputId": "41f12f03-7583-4725-8e87-cffb40a18970"
   },
   "outputs": [],
   "source": [
    "#optional cell if using drive:\n",
    "#if using drive the file creeation will not work!\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd32b7",
   "metadata": {
    "id": "a2dd32b7"
   },
   "source": [
    "\n",
    "\n",
    "# Section 0: Getting data from million songs playlists\n",
    "\n",
    "### How to use this notebook\n",
    "\n",
    "1. Download it\n",
    "2. Download and extract the million songs dataset (link in the README.md on the repo) in the same directory as this notebook\n",
    "3. Set the DIRECTORY constant in the cell below as the directory containing the dataset\n",
    "4. You should then be able to run all of it\n",
    "\n",
    "Section 1 is making a graph to figure out how the number of followers over all the playlists is distributed\n",
    "Section 2 is removing all playlists from the dataset which have N or more fewer, and creating a new file containing playlists with only more than N followers\n",
    "Section 3 is extracting N songs randomly from a given dataset, either randomly or with a weighted random distribution. You can set the constants to change the sampling method, number of songs, and the dataset you are computing over. If you use the default dataset to pick the songs, it is quite slow (takes like 10 minutes overall), so you may want to use a smaller dataset to choose these songs. I set the dataset to the dataset containing playlists with over 5 followers and it is significantly quicker to run. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561efd48",
   "metadata": {},
   "source": [
    "### IMPORTANT: Set the directory containing the data below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f900x3nJpM8J",
   "metadata": {
    "id": "f900x3nJpM8J"
   },
   "outputs": [],
   "source": [
    "DIRECTORY = \"spotify_million_playlist_dataset/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f57447f",
   "metadata": {
    "id": "1f57447f"
   },
   "source": [
    "### 1. Figuring out distribution of number of followers over playlists\n",
    "\n",
    "This is just to figure out what the distribution of the followers looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e38ec2a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e38ec2a",
    "outputId": "53f204b0-95ba-4175-f7e2-2bc407691d54"
   },
   "outputs": [],
   "source": [
    "# 1. Followers numbers\n",
    "# 10,000 songs choose (Quanchi's link)\n",
    "\n",
    "\n",
    "num_followers = []\n",
    "directory = os.listdir(DIRECTORY)\n",
    "\n",
    "for file in directory:\n",
    "\n",
    "    f = open(DIRECTORY+file)\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "    for playlist in range(len(data['playlists'])):\n",
    "        x = data['playlists'][playlist]['num_followers']\n",
    "        num_followers += [x]\n",
    "\n",
    "num_followers = pd.Series(num_followers)\n",
    "num_followers.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd9d657",
   "metadata": {
    "id": "5dd9d657"
   },
   "outputs": [],
   "source": [
    "num_likes = {}\n",
    "\n",
    "for val in num_followers:\n",
    "    if val in num_likes:\n",
    "        num_likes[val] += 1\n",
    "    else:\n",
    "        num_likes[val] = 1\n",
    "\n",
    "keys = []\n",
    "for key in num_likes.keys():\n",
    "    keys += [key]\n",
    "\n",
    "keys.sort()\n",
    "\n",
    "X,y = [],[]\n",
    "\n",
    "for key in keys:\n",
    "    X +=[key]\n",
    "    y +=[num_likes[key]]\n",
    "    \n",
    "    \n",
    "#make the y-values a fraction of the size of the dataset\n",
    "y_c = y     \n",
    "for i in range(len(y_c)):\n",
    "        y_c[i] = (y_c[i]+y_c[i-1])\n",
    "\n",
    "for i in range(len(y_c)):\n",
    "    y_c[i]/= 1000000\n",
    "\n",
    "y_c\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae833b8",
   "metadata": {
    "id": "4ae833b8"
   },
   "outputs": [],
   "source": [
    "#Plot\n",
    "\n",
    "plt.plot(X[:40], y[:40],linestyle=\"-\", marker=\"o\")\n",
    "plt.ylabel(\"Fraction of playlists with followers <= than this number\")\n",
    "plt.xlabel(\"Number of Followers\")\n",
    "plt.xticks(np.arange(0,41,2))\n",
    "plt.show()\n",
    "f = plt.figure()\n",
    "f.set_figwidth(1)\n",
    "f.set_figheight(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5556a4cf",
   "metadata": {
    "id": "5556a4cf"
   },
   "outputs": [],
   "source": [
    "print(1000000 - y_c[5]*1000000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0622574",
   "metadata": {
    "id": "f0622574"
   },
   "source": [
    "### 2. Removing the majority of the playlists\n",
    "\n",
    "Removing all playlists with N or less followers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca01a8",
   "metadata": {
    "id": "a8ca01a8"
   },
   "outputs": [],
   "source": [
    "N = 10\n",
    "directory = os.listdir(DIRECTORY)\n",
    "\n",
    "moreThanN = []\n",
    "\n",
    "for file in directory:\n",
    "\n",
    "    f = open(DIRECTORY+file)\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "    for playlist in range(len(data['playlists'])):\n",
    "        if data['playlists'][playlist]['num_followers'] >N:  \n",
    "            moreThanN += [data['playlists'][playlist]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7877ad0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7877ad0",
    "outputId": "67370876-3a87-4d5b-e9b2-602ca77fc6a4"
   },
   "outputs": [],
   "source": [
    "#sanity check\n",
    "\n",
    "len(moreThanN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GJeLZslQm0-c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJeLZslQm0-c",
    "outputId": "ba4ac40c-6a8b-457c-84b2-7247c3b836bd"
   },
   "outputs": [],
   "source": [
    "#Create results folder\n",
    "\n",
    "path = os.getcwd()+\"/generated_data\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path)\n",
    "   print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161047a2",
   "metadata": {
    "id": "161047a2"
   },
   "outputs": [],
   "source": [
    "#SAVING DATA\n",
    "#convert to dictionary \n",
    "moreThanN_dict = {\"playlists\": moreThanN}\n",
    "\n",
    "json_object = json.dumps(moreThanN_dict, indent=4)\n",
    "with open(path+\"/moreThan\"+str(N)+\"followers.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125c42e",
   "metadata": {
    "id": "8125c42e"
   },
   "outputs": [],
   "source": [
    "#formatting stuff for .edges filef\n",
    "\n",
    "data = \"\"\n",
    "\n",
    "for key in edges:\n",
    "    data+= (key + ' ' + str(edges[key])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7163505d",
   "metadata": {
    "id": "7163505d"
   },
   "outputs": [],
   "source": [
    "#writing the truncated data to a new .json file\n",
    "\n",
    "with open(path+\"/moreThan\"+str(N)+\"followers.edges\", \"w\") as outfile:\n",
    "    outfile.write(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caa0ad4",
   "metadata": {
    "id": "6caa0ad4"
   },
   "source": [
    "### 3. Choosing our songs and generating data\n",
    "\n",
    "Selecting N songs randomly and performing an analysis on them.\n",
    "\n",
    "Change the constants in the cell below to change the kind of data you create.\n",
    "\n",
    "The output of these cells will be a .csv file in the generated_data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28dc57f",
   "metadata": {
    "id": "e28dc57f"
   },
   "outputs": [],
   "source": [
    "################# Constants #################\n",
    "'''Rename this constant to the file containing the data, otherwise it will go through all of the data.\n",
    "I recommend using a file generated by Method 1 as the specific file (for instance, moreThan10followers.json) since\n",
    "the computation times will be much much faster'''\n",
    "SPECIFIC_FILE = 'generated_data/moreThan10followers.json' \n",
    "\n",
    "WEIGHTED_RANDOM = False   #If we want weighted random sampling or not\n",
    "N = 2000  #number of songs to consider\n",
    "\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f26d39",
   "metadata": {
    "id": "b8f26d39"
   },
   "outputs": [],
   "source": [
    "\n",
    "#first we need to load all the songs into a dictionary so that we can randomly select N of them\n",
    "\n",
    "\n",
    "all_tracks = {} #stores all the songs\n",
    "count = 0 #progress bar\n",
    "\n",
    "\n",
    "if SPECIFIC_FILE == '':\n",
    "    directory = os.listdir(DIRECTORY)\n",
    "    for file in directory:\n",
    "        count +=1\n",
    "        if (count %100 == 0):\n",
    "            print(count)\n",
    "        f = open(DIRECTORY+file)\n",
    "        data = json.load(f)\n",
    "\n",
    "        for playlist in data['playlists']:\n",
    "            for track in playlist['tracks']:\n",
    "                if track['track_name'] not in all_tracks:  #if it not in the dict then we add it to it and increase its weight\n",
    "                    all_tracks[track['track_name']] = 1 #weight is used for weighted random sampling (if needed)\n",
    "                else:\n",
    "                    all_tracks[track['track_name']] +=1\n",
    "                \n",
    "############### TO LOOP OVER SOME SMALLER FILE ##################\\\n",
    "else:\n",
    "    f = open(SPECIFIC_FILE)\n",
    "    data = json.load(f)\n",
    "\n",
    "    for playlist in data['playlists']:\n",
    "        for track in playlist['tracks']:\n",
    "            if track['track_name'] not in all_tracks:  #if it not in the dict then we add it to it and increase its weight\n",
    "                all_tracks[track['track_name']] = 1 #weight is used for weighted random sampling (if needed)\n",
    "            else:\n",
    "                all_tracks[track['track_name']] +=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f183cb6",
   "metadata": {
    "id": "8f183cb6",
    "outputId": "67815257-8bde-4172-9909-66ed1106da4d"
   },
   "outputs": [],
   "source": [
    "print(list(all_tracks.keys())[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbf342",
   "metadata": {
    "id": "98fbf342"
   },
   "outputs": [],
   "source": [
    "#get N songs based on weighted random sampling (no particular reason for this apart from probably giving a more connected NW)\n",
    "\n",
    "if WEIGHTED_RANDOM == False:\n",
    "    songs = random.choices(list(all_tracks.keys()), weights=None, k=N)\n",
    "else:\n",
    "    songs = random.choices(list(all_tracks.keys()), weights=all_tracks.values(), k=N)\n",
    "\n",
    "\n",
    "songs = set(songs) #convert to set\n",
    "print(songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac8264",
   "metadata": {
    "id": "8cac8264",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now I want to create a list of shared playlists\n",
    "\n",
    "shared_playlists = [] #this will contain items of the form (weight: [weight], tracks: [tracks]) for each playlist\n",
    "\n",
    "if SPECIFIC_FILE == '':\n",
    "    for file in directory:\n",
    "        f = open(DIRECTORY+file) \n",
    "        data = json.load(f)\n",
    "\n",
    "        for playlist in data['playlists']:  #parse through every playlist\n",
    "\n",
    "            num_followers = playlist['num_followers']\n",
    "\n",
    "            temp = []\n",
    "\n",
    "            for track in playlist['tracks']:\n",
    "                if track['track_name'] in songs and track['track_name'] not in temp:\n",
    "                    temp.append(track['track_name'])\n",
    "\n",
    "            if (len(temp) >1): #only if a playlist has two or more of the 10k songs then we add it to our shared_playlists lits\n",
    "                item = {'weight':num_followers, 'tracks':temp}\n",
    "                shared_playlists.append(item)\n",
    "\n",
    "else:\n",
    "    \n",
    "    f = open(SPECIFIC_FILE) \n",
    "    data = json.load(f)\n",
    "\n",
    "    for playlist in data['playlists']:  #parse through every playlist\n",
    "\n",
    "        num_followers = playlist['num_followers']\n",
    "\n",
    "        temp = []\n",
    "\n",
    "        for track in playlist['tracks']:\n",
    "            if track['track_name'] in songs and track['track_name'] not in temp:\n",
    "                temp.append(track['track_name'] + \", by \"+ track['artist_name'])\n",
    "\n",
    "        if (len(temp) >1): #only if a playlist has two or more of the 10k songs then we add it to our shared_playlists lits\n",
    "            item = {'weight':num_followers, 'tracks':temp}\n",
    "            shared_playlists.append(item)\n",
    "\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e02efa",
   "metadata": {
    "id": "51e02efa"
   },
   "outputs": [],
   "source": [
    "#create edges\n",
    "edges = {}\n",
    "count = 0\n",
    "for item in shared_playlists:\n",
    "\n",
    "    weight = item['weight']\n",
    "    tracks = item['tracks']\n",
    "    for track1 in tracks:\n",
    "        for track2 in tracks:\n",
    "            if (track1 == track2):\n",
    "                continue\n",
    "            if (track1,track2) in edges:\n",
    "                edges[(track1,track2)] += weight\n",
    "            elif ((track2,track1)) in edges:\n",
    "                edges[(track2,track1)] += weight\n",
    "            else:\n",
    "                edges[(track1,track2)] = weight\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(edges.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ca21b2",
   "metadata": {
    "id": "87ca21b2"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for key in edges:\n",
    "    temp = (key[0],key[1],edges[key]) #make tuple of form (song1, song2, weight)\n",
    "    data.append(temp)\n",
    "data2 = pd.DataFrame(data)\n",
    "data2.columns = [\"Source\",\"Target\",\"Weight\"]\n",
    "print(data2[0:5]) #sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create results folder\n",
    "\n",
    "path = os.getcwd()+\"/generated_data\"\n",
    "# Check whether the specified path exists or not\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "\n",
    "   # Create a new directory because it does not exist\n",
    "   os.makedirs(path)\n",
    "   print(\"The new directory is created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82ee63",
   "metadata": {
    "id": "6f82ee63"
   },
   "outputs": [],
   "source": [
    "#Writing the file\n",
    "\n",
    "name = \"\"\n",
    "\n",
    "if (WEIGHTED_RANDOM == True):\n",
    "    name = str(N) + '_weighted'\n",
    "else:\n",
    "    name = str(N)\n",
    "filename = path+'/'+name+\"_random_songs.csv\"\n",
    "filepath = Path(filename)\n",
    "while (os.path.exists(filepath)):\n",
    "    if filename[-5]=='s':\n",
    "        filename = filename[:-4]+'2'+filename[-4:]\n",
    "    else:\n",
    "        filename = filename[:-5]+str(int(filename[-5])+1)+filename[-4:]\n",
    "    filepath = Path(filename)\n",
    "\n",
    "data2.to_csv(filepath, index = False)\n",
    "    \n",
    "    \n",
    "#The data should be saved in the same folder as this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab9394",
   "metadata": {
    "id": "4eab9394"
   },
   "source": [
    "## Thoughts so far\n",
    "\n",
    "- Selecting playlists above a certain number of likes produces a very dense network even with only the top 600~ networks\n",
    "- Selecting 10k songs randomly produces a pretty sparse network with some intereseting communities\n",
    "- Selecting 10k songs randomly with a weighted distribution produces an extremely dense network\n",
    "- The clustering coefficient for 100 random weighted songs is small (0.04), but when we pick 500 random weighted songs it grows larger (0.34). For 10000 random songs it was like 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d3b002",
   "metadata": {},
   "source": [
    "# Section 1: Defining the edges of the network\n",
    "\n",
    "In this section we explore several different means to quantify how similar one song is to another. We will use these similarity scores to assign weights to the edges of our network. \n",
    "\n",
    "### Idea 1: Shared Followers\n",
    "This method assigns a weight to each edge based on the sum of likes of each playlist that both songs in the edge appear in.\n",
    "\n",
    "$w_{i,j} = \\Sigma_{p \\in P_{i,j}}{\\normalsize \\text{# likes of }p}$, where $P_{i,j}$ is the set of playlists contatining songs $i$ and $j$\n",
    "\n",
    "### Idea 2: Shared Playlists\n",
    "The weight of each edge is the number of shared playlists of the song\n",
    "\n",
    "$w_{i,j} = \\normalsize |P_{i,j}|$\n",
    "\n",
    "### Idea 3: Hybrid of 1 and 2\n",
    "Since the follower numbers of the playlists are heavily skewed, ranging from 1 to over 70k, we experiment with weighting the shared playlist number higher than the shared follower number.\n",
    "\n",
    "$w_{i,j} = \\normalsize |P_{i,j}| + log_2({\\Sigma_{p \\in P_{i,j}}{\\text{# likes of }p}})$\n",
    "\n",
    "For our purposes, we use $log_2$ to weight the follower numbers as we think it suits our data well.\n",
    "\n",
    "### Idea 4: Shared Playlist Simliarity\n",
    "\n",
    "Let $p_{i,j}$ denote the fraction of playlists that song $i$ belongs to which also contain song $j$. \n",
    "Then, $ w_{i,j} = \\large \\frac{p_{i,j}\\cdot p_{j,i}}{2}$\n",
    "\n",
    "I.e, this is the average of the fraction of all playlists containing one song that also contain the other\n",
    "\n",
    "\n",
    "## TODO: Define functions that implement each of these ideas\n",
    "\n",
    "Each function should take in a set of N songs, an input file (not the whole dataset as that is way too big!) and return two things: 1. The edges of the graph created by each method, and 2. A dictionary of node relations to each other.\n",
    "\n",
    "\n",
    "So what we're doing here is \n",
    "- selecting N songs (like 10k out of the million) out of the input file (has more than N songs).  \n",
    "- We want to remember only the playlists with two or more of the N songs in them. For that playlist, we remember it as a pair of (weight, [tracks out of the N in that playlist]) (but you could play around with this to see what works) \n",
    "- Then, using the cleaned up, relevant playlists with their weights (that we did in the previous step) we make the graph, which is a dictionary of the form { {(node1,node2), weight} }. So, the key is (node1,node2) and the corresponding value is weight\n",
    "\n",
    "Ultimately the output should be the network with the weights aligned with each of the above ideas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcd89b2",
   "metadata": {
    "id": "3fcd89b2"
   },
   "source": [
    "# Section 2: Implementing algorithm to generate playlists\n",
    "\n",
    "## 2.1: Star Graph Algorithm\n",
    "\n",
    "Here I'll try to create the playlists using the star graph recommendation method. For this I need two things - first is a recommendation algorithm based on the edges, and second is an easy way to iterate over song connections. \n",
    "\n",
    "### How this works:\n",
    "\n",
    "First we consider the one node case. We feed a single node, call it node A, into the algorithm which gives us the subset of the network with one edge at A, which is a star graph. We store this star graph in a dictionary object. The next song to be recommended is one of the edges in this graph, randomly chosen with a weighted probability distribution. Call this song B. Now, we want the playlist that we are generating to be the center of the star graph. Now, we make the center of the star graph represent both nodes A and B. We add all the edges with end to B (except those with end A) from the original dataset to the star graph. If an edge already exists between the center and another node, and B is also connected with that node, the new weight of that edge becomes the sum of the weights of those edges. This is to implement familiarity. Continue this until the desired playlist size is reached. \n",
    "\n",
    "\n",
    "### TODO:\n",
    "- If we can create functions for creating the edge weights of the network that would be totally awesome\n",
    "- Perhaps cosine simliarity would be a good thing to explore for our recommendations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c642371c",
   "metadata": {
    "id": "c642371c"
   },
   "source": [
    "Running the two cells below will initialize the network. There are some constants at the start that you need to input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4522710d",
   "metadata": {
    "id": "4522710d"
   },
   "outputs": [],
   "source": [
    "######################################### Constants\n",
    "\n",
    "SPECIFIC_FILE = 'generated_data/moreThan10followers.json' #Rename this to something else if you want to only consider some other dataset, \n",
    "                    #otherwise we go over all data. specify the file name/path as the name\n",
    "WEIGHTED_RANDOM = False   #If we want weighted random sampling or not\n",
    "N = 1000  #number of songs to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80f0f40",
   "metadata": {
    "id": "d80f0f40"
   },
   "outputs": [],
   "source": [
    "######################################### LOADING SONGS FROM FILE\n",
    "#first we need to load all the songs into a dictionary so that we can randomly select N of them\n",
    "\n",
    "\n",
    "all_tracks = {} #stores all the songs\n",
    "count = 0 #progress bar\n",
    "\n",
    "\n",
    "f = open(SPECIFIC_FILE)\n",
    "data = json.load(f)\n",
    "\n",
    "for playlist in data['playlists']:\n",
    "    for track in playlist['tracks']:\n",
    "        if track['track_name'] not in all_tracks:  #if it not in the dict then we add it to it and increase its weight\n",
    "            all_tracks[track['track_name']] = 1 #weight is used for weighted random sampling (if needed)\n",
    "        else:\n",
    "            all_tracks[track['track_name']] +=1\n",
    "\n",
    "\n",
    "######################################### CHOOSING RANDOM SONGS\n",
    "\n",
    "if WEIGHTED_RANDOM == False:\n",
    "    songs = random.choices(list(all_tracks.keys()), weights=None, k=N)\n",
    "else:\n",
    "    songs = random.choices(list(all_tracks.keys()), weights=all_tracks.values(), k=N)\n",
    "\n",
    "#print(songs)\n",
    "\n",
    "######################################### CREATING SHARED PLAYLIST EDGES\n",
    "\n",
    "shared_playlists = [] #this will contain items of the form (weight: [weight], tracks: [tracks]) for each playlist\n",
    "\n",
    "\n",
    "f = open(SPECIFIC_FILE) \n",
    "data = json.load(f)\n",
    "\n",
    "for playlist in data['playlists']:  #parse through every playlist\n",
    "\n",
    "    num_followers = playlist['num_followers']\n",
    "    temp = []\n",
    "    for track in playlist['tracks']: #if one of the random songs is in the playlist then remember it\n",
    "        if track['track_name'] in songs and track['track_name'] not in temp:\n",
    "            temp.append(track['track_name'])\n",
    "\n",
    "    if (len(temp) >1): #only if a playlist has two or more of the 10k songs then we add it to our shared_playlists lits\n",
    "        item = {'weight':num_followers, 'tracks':temp}\n",
    "        shared_playlists.append(item)\n",
    "\n",
    "\n",
    "# #Here we create the big graph\n",
    "edges = {}\n",
    "relations = {} #this variable stores all of the node pairs in the graph. It is useful for the playlist-generation part of the notebook\n",
    "for song in songs:\n",
    "    relations[song] = set({})\n",
    "\n",
    "for item in shared_playlists:\n",
    "    \n",
    "    weight = item['weight']\n",
    "    tracks = item['tracks']\n",
    "    for track1 in tracks:\n",
    "        for track2 in tracks:\n",
    "            if (track1 == track2):\n",
    "                continue\n",
    "            #now we add relations\n",
    "            if track2 not in relations[track1]:\n",
    "                relations[track1].add(track2)\n",
    "            if track1 not in relations[track2]:\n",
    "                relations[track2].add(track1)\n",
    "                \n",
    "            #now create edge and weight\n",
    "            if (track1,track2) not in edges and (track2,track1) not in edges:\n",
    "                edges[(track1,track2)] = weight\n",
    "                edges[(track2,track1)] = weight\n",
    "            else:\n",
    "                edges[(track1,track2)] += weight\n",
    "                edges[(track2,track1)] += weight\n",
    "\n",
    "\n",
    "print(\"Some songs that were selected:\")\n",
    "print(songs[0:5])\n",
    "print('\\n')\n",
    "print(\"Some of the edges that were created:\")\n",
    "print(list(edges.items())[0:5])\n",
    "print('\\n')\n",
    "print(\"Some of the pairs of nodes in the graph:\\n\")\n",
    "for n in range(5):\n",
    "    i = random.randint(0,len(songs))\n",
    "    print(\"Track:\"+str(songs[i]))\n",
    "    print(\"Tracks it is related to:\")\n",
    "    print(relations[songs[i]])\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f01ed",
   "metadata": {
    "id": "f44f01ed"
   },
   "source": [
    "The cell below defines the function that we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7922166f",
   "metadata": {
    "id": "7922166f"
   },
   "outputs": [],
   "source": [
    "def recommend_song(stargraph, songs, alpha = 1):\n",
    "    '''\n",
    "    Function that will implement the recommend algorithm for a given input star graph. We are assigning weights to every \n",
    "    song in the number of songs we are operating over. The weight of each song will be the weight of the edge from it to the\n",
    "    center of the stargraph (0 otherwise) + alpha. We will then make a weighted random prediction to get the next song.\n",
    "    \n",
    "    Parameters:\n",
    "        stargraph: the input star graph. The first element is the nodes inside the graph and the second one is a dictionary \n",
    "        of node:weight pairs\n",
    "        songslist: the list of songs over which we are operating\n",
    "        alpha: value to give to every song to allow possible recommendation of songs without any edges (teleportation). 1 by default\n",
    "  \n",
    "  Returns:\n",
    "       The predicted song\n",
    "   '''\n",
    "    weights = []\n",
    "    for i in range(len(songs)):\n",
    "        song = songs[i]\n",
    "        weight = alpha\n",
    "        if song in stargraph[1]: #if there is already an edge to it\n",
    "            weight+= stargraph[1][song]\n",
    "        if song in stargraph[0]: #if it is already in our playlist\n",
    "            weight = 0\n",
    "        weights.append(weight)\n",
    "    nextsong = random.choices(songs, weights, k=1)[0] #return our weighted random choice\n",
    "    #print (nextsong)\n",
    "    return nextsong\n",
    "\n",
    "def update_graph(stargraph, songToAdd, relations, edges):\n",
    "    '''\n",
    "    Function that will update the star graph to include edges that belong to the song to add. Returns updated star graph\n",
    "    \n",
    "    Parameters:\n",
    "        stargraph: the input star graph. The first element is the nodes inside the graph and the second one is a dictionary \n",
    "        of node:weight pairs\n",
    "        songToAdd: the song to add\n",
    "        relations: the dictionary of all pairs in the graph\n",
    "        edges: the original network with all the node pair relations\n",
    "   \n",
    "   Returns:\n",
    "        The updated star graph\n",
    "    '''\n",
    "    relationsToAdd = relations[songToAdd] #give a set of all the pairs of nodes with the song to add\n",
    "    stargraphNodes = stargraph[0]\n",
    "    stargraphEdges = stargraph[1]\n",
    "    \n",
    "    for song in relationsToAdd: #go through each pair belonging to this song\n",
    "        \n",
    "        if song not in stargraphNodes:\n",
    "            if song not in stargraphEdges:\n",
    "                stargraphEdges[song] = edges[(song,songToAdd)] #add value of edge from the original network\n",
    "            else:\n",
    "                stargraphEdges[song] += edges[(song,songToAdd)]\n",
    "                \n",
    "    stargraph[0].add(songToAdd)\n",
    "    return stargraph\n",
    "    \n",
    "    \n",
    "def create_playlist(inputSongs, length,  songs, relations, edges,alpha = 1):\n",
    "    '''\n",
    "    Function that generates a recommendation playlist of length length based on an input of songs, and an input network\n",
    "    \n",
    "    Parameters:\n",
    "    inputSongs: The input songs (list)\n",
    "    length: Number of songs to add\n",
    "    songs: List of all songs\n",
    "    relations: Dictionary of all pair relations in the graph\n",
    "    edges: The original network\n",
    "    alpha: The teleportation probability in the recommendation algorithm\n",
    "    '''\n",
    "    stargraph = (set(), dict())\n",
    "    \n",
    "    for song in inputSongs: #build the star graph\n",
    "        stargraph = update_graph(stargraph, song, relations, edges) \n",
    "    \n",
    "    for i in range(length):\n",
    "        newSong = recommend_song(stargraph, songs, alpha)\n",
    "        stargraph = update_graph(stargraph, newSong, relations, edges)\n",
    "    \n",
    "    return list(stargraph[0])\n",
    "    \n",
    "    \n",
    "            \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7806d8c0",
   "metadata": {
    "id": "7806d8c0"
   },
   "source": [
    "## Using the algorithm\n",
    "\n",
    "Finally, the cell below tests the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d794292e",
   "metadata": {
    "id": "d794292e",
    "outputId": "6ef5bc56-23dc-4140-f58d-2178aff41fc5"
   },
   "outputs": [],
   "source": [
    "#Testing the algorithm\n",
    "\n",
    "playlist = []\n",
    "for i in range(3):\n",
    "    playlist.append(songs[random.randint(0,len(songs))])\n",
    "length = len(playlist)+10\n",
    "print(\"Input songs:\")\n",
    "print(playlist)\n",
    "playlist = create_playlist(playlist, length, songs, relations, edges)\n",
    "print(\"Generated playlist:\")\n",
    "print(playlist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5f0a9c",
   "metadata": {
    "id": "fc5f0a9c"
   },
   "source": [
    "### Thoughts on algorithm\n",
    "\n",
    "I have no idea if these are great playlists or not lmao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd2c770",
   "metadata": {},
   "source": [
    "## 2.2 Cosine Simliarity\n",
    "\n",
    "### TODO\n",
    "- maybe this would be good for idea #4 of Section 1 since the weights are all normalized and in the [0,1] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e847f4a",
   "metadata": {
    "id": "1e847f4a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
